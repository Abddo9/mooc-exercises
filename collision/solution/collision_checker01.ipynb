{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision checking\n",
    "\n",
    "As part of this exercise, you will write your very own collision checker. While this checker will only function in-simulation, it should give you a good idea of the complexity associated with detecting collisions in the real world.\n",
    "\n",
    "We have defined a few data structures that you will use in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures and protocol\n",
    "\n",
    "The data structures are defined in the `dt-protocols-daffy` package.\n",
    "\n",
    "In particular, you can look in [`collision_protocol.py`][file] the data structures to use.\n",
    "\n",
    "We **strongly** suggest opening the [`collision_protocol.py`][file] link/file in a separate window, and cross-referencing the information given here with the code definition given in the file.\n",
    "\n",
    "[file]: https://github.com/duckietown/dt-protocols/blob/daffy/src/dt_protocols/collision_protocol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for the collision checker are a `MapDefinition`, which specifies the `environment`, and `body`.\n",
    "\n",
    "Both `environment` and `body` are lists of `PlacedPrimitive`s.\n",
    "\n",
    "A `PlacedPrimitive` is a pair of a `FriendlyPose` and a `Primitive`.\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PlacedPrimitive:\n",
    "    pose: FriendlyPose\n",
    "    primitive: Primitive\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class FriendlyPose:\n",
    "    x: float\n",
    "    y: float\n",
    "    theta_deg: float\n",
    "```\n",
    "\n",
    "A `FriendlyPose` is a handy pose representation containing a (x,y) coordinate along with an angle. How friendly!\n",
    "\n",
    "A `Primitive` is either a `Rectangle` or a `Circle`.\n",
    "\n",
    "```python\n",
    "\n",
    "@dataclass\n",
    "class Circle:\n",
    "    radius: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Rectangle:\n",
    "    xmin: float\n",
    "    ymin: float\n",
    "    xmax: float\n",
    "    ymax: float\n",
    "\n",
    "Primitive = Union[Circle, Rectangle]\n",
    "```\n",
    "\n",
    "So, we represents shapes as a union of rototranslated `Rectangle`s and `Circle`s.\n",
    "\n",
    "The collision checker receives first a message `MapDefinition`, and then a sequence of `CollisionCheckQuery`s. The query contains a pose for the robot, which you will need to cross-reference against the `MapDefinition` to detect collisions. The `CollisionCheckResult` contains only a boolean: true means that it is in collision, false means that it is not in collision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template\n",
    "\n",
    "In [`collision_checker.py`][file] you will find the template for the collision checker.\n",
    "\n",
    "[file]: ./collision_checker.py\n",
    "\n",
    "## Visualization\n",
    "\n",
    "The challenge's output will be a series of images in a folder that is output at the end of the evaluation. The path will be something like:\n",
    "\n",
    "`/tmp/![username]/duckietown/dt-challenges-runner/local-evals/mooc-collision-check-vali/![date]/step1/tmp/![random]/`\n",
    "\n",
    "In the `images` folder you will see the queries with the ground truth,\n",
    "as the image shows.\n",
    "\n",
    "![query](media/env18.png)\n",
    "\n",
    "Colors:\n",
    "\n",
    "- $\\color{blue}{\\text{Blue}}$ is a pose in which the robot does not collide.\n",
    "- $\\color{red}{\\text{Red}}$ is a pose in which the robot collides.\n",
    "\n",
    "In the `results` folder you will see your results and the errors you made:\n",
    "\n",
    "![result](media/env18-result.png)\n",
    "\n",
    "The colors mean the following:\n",
    "\n",
    "- $\\color{blue}{\\text{Blue}}$ is a pose in which the robot does not collide and you guessed **RIGHT**.\n",
    "- $\\color{orange}{\\text{Orange}}$ is a pose in which the robot does not collide and you guessed **WRONG**.\n",
    "- $\\color{red}{\\text{Red}}$ is a pose in which the robot collides and you guessed **RIGHT**.\n",
    "- $\\color{pink}{\\text{Pink}}$ is a pose in which the robot collides and you guessed **WRONG**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for implementing the collision checker\n",
    "\n",
    "There are multiple ways to implement the collision checker. Here are some tips, but feel free to follow your intuition.\n",
    "\n",
    "### Use decomposition\n",
    "\n",
    "The first thing to note is that the problem can be *decomposed*.\n",
    "\n",
    "You are asked to see whether the robot collides with the environment at a certain pose.\n",
    "Both robot and environment are lists of `Primitive`s. In pseudocode:\n",
    "\n",
    "    robot =  robot_part_1 ∪ rp2 ∪ rp3 ... \n",
    "    Wcoll =  world_collision_1 ∪ wc2 ∪ wc3 ...\n",
    "\n",
    "What you have to check is whether the intersection\n",
    "\n",
    "    robot ∩ Wcoll \n",
    "\n",
    "is empty. Expanding:\n",
    "\n",
    "    (rp1 ∪ rp2 ∪ ... ) ∩ (wc1 ∪ wc2 ∪ ...)\n",
    "\n",
    "Now, the intersection of unions is a union of intersection:\n",
    "\n",
    "    [rp1 ∩ (wc1 ∪ wc2 ∪ ...)]  ∪  [rp2 ∩ (wc1 ∪ wc2 ∪ ...)] ∪ ...\n",
    "\n",
    "The above shows that you have to check whether any primitive of the robot collides with environment.\n",
    "\n",
    "Further expanding the first term we obtain:\n",
    "\n",
    "    [rp1 ∩ (wc1 ∪ wc2 ∪ ...)] = (rp1 ∩ wc1) ∪ (rp2 ∩ wc1) ∪ ...\n",
    "\n",
    "which shows that in the end, you can reduce the problem to checking pairwise intersection of primitives.\n",
    "\n",
    "In other words...\n",
    "\n",
    "```\n",
    "for each environment_shape in env:\n",
    "    for each robot_part in robot:\n",
    "        if collides:\n",
    "            return True\n",
    "return False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention to the poses\n",
    "\n",
    "Both robot and environment are lists of **rototranslated** primitives.\n",
    "\n",
    "That is, we should rewrite the robot expression as:\n",
    "\n",
    "    robot = RT(pose1, primitive1) ∪ RT(pose2, primitive1) ∪ ...\n",
    "\n",
    "where `RT()` rototranslates a primitive by a pose.\n",
    "\n",
    "Also note that for each collision-checking query the robot changes pose. Let's call the current robot pose `Q`.\n",
    "\n",
    "Note that we have\n",
    "\n",
    "    robot at pose Q = RT(Q * pose1, primitive1) ∪ RT(Q * pose2, primitive1) ∪ ... \n",
    "\n",
    "where `Q * pose` represent matrix multiplication.\n",
    "\n",
    "The above says that you can \"push inside\" the global pose.\n",
    "\n",
    "### In the end, what is the core complexity?\n",
    "\n",
    "Following the above tips, you should be able to get to the point where you are left with checking the collision of two rototranslated primitives.\n",
    "\n",
    "Note that without loss of generality you can get to the point where you have one primitive at the origin. (You put one primitive in the coordinate frame of the other.)\n",
    "\n",
    "Now notice that there are 3 cases:\n",
    "\n",
    "- `Rectangle` vs `Circle`\n",
    "- `Rectangle` vs `Rectangle`\n",
    "- `Circle` vs `Circle`\n",
    "\n",
    "`Circle` vs `Circle` is easy: two circles intersects if the distance of the centers is less than the sum of the radii.\n",
    "\n",
    "For the others, you will have to think about it...\n",
    "\n",
    "### Speeding things up using lower/upper bound heuristics\n",
    "\n",
    "If you want to speed things up, consider the following method, which allows to introduce a fast heuristic phase using only circle-to-circle comparisons.\n",
    "\n",
    "For each rectangle `R`, you can find `C1`, the largest circle that is contained in the rectangle, and `C2`, the smallest circle that contains the rectangle. These are an upper bound and a lower bound to the shape.\n",
    "\n",
    "    C1 ⊆ R ⊆ C2\n",
    "\n",
    "Now notice that:\n",
    "\n",
    "- if `C1` collides with a shape, also `R` does.  (but if it doesn't you cannot conclude anything)\n",
    "- if `C2` does not collide with a shape, `R` does not as well. (but if it does, you cannot conclude anything)\n",
    "\n",
    "Using this logic, you can implement a method that first checks quickly whether the circle approximations give already enough information to conclude collision/no-collision. Only if the first test is inconclusive you go to the more expensive component.\n",
    "\n",
    "### Speeding things up using bitmaps heuristics\n",
    "\n",
    "Another approach is using bitmaps to convert the environment to an image, where a black pixel means \"occupied\", and a white pixel means \"free\". \n",
    "\n",
    "Then you can do the same with the robot shape and obtain another bitmap.\n",
    "\n",
    "Then you check whether the two bitmaps intersect\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- reduces the problem of collision to drawing of shapes;\n",
    "- cheaper if shapes are very complex.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- There are subtle issues regarding the approximations you are making. What exactly does a pixel represent? is it a point, or is it an area? is this an optimistic or pessimistic approximation? The semantics of painting is unclear. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
